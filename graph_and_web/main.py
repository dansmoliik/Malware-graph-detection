import sys
from os import path, makedirs, chdir
import ntpath
import filter_data
from make_graph import mk_graph, find_max_number_of_edges
from input_processing import process_input_args
from find_loops import get_loops_in_range
from other_functions import console_print


def save_data_to_file(file_name, ip_address, what_to_save, data):
    dir_name = "output"
    if not path.isdir(dir_name):
        makedirs(dir_name)
    file_name = file_name.split(".binetflow")[0]
    dir_name = path.join(dir_name, file_name)
    if not path.isdir(dir_name):
        makedirs(dir_name)
    dir_name = path.join(dir_name, ip_address)
    if not path.isdir(dir_name):
        makedirs(dir_name)
    file_name = ntpath.basename(file_name)
    file_name_ending = ""
    if what_to_save == "graph_json":
        file_name_ending = "_graph.json"
    else:
        if what_to_save == "al_nodes":
            file_name_ending = "_al-nodes"
        elif what_to_save == "edges":
            file_name_ending = "_edges"
        elif what_to_save == "loops":
            file_name_ending = "_loops"
        elif what_to_save == "overall":
            file_name_ending = "_overall"
        file_name_ending += ".md"
    file_name += "_" + ip_address + file_name_ending
    with open(path.join(dir_name, file_name), "w") as f:
        f.write(data)


def print_list_node_names_counts(nodes, counts):
    out_str = "---------------\n"
    for i in range(0, len(nodes)):
        out_str += "{:<30}{:>10}\n".format(nodes[i], counts[i])
    out_str += "---------------\n"
    console_print(out_str)


def save_al_nodes_to_file(file_name, ip_address, nodes, counts):
    data = ""
    for i in range(0, len(nodes)):
        data += "{:<30}{:>10}\n".format(nodes[i], counts[i])
    save_data_to_file(file_name, ip_address, "al_nodes", data)


def print_list_edges_counts(src_nodes, dst_nodes, counts):
    out_str = "---------------\n"
    for i in range(0, len(src_nodes)):
        out_str += "{:<30}=>{:>30}{:>10}\n".format(src_nodes[i], dst_nodes[i], counts[i])
    out_str += "---------------\n"
    console_print(out_str)


def save_edges_to_file(file_name, ip_address, src_nodes, dst_nodes, counts):
    data = ""
    for i in range(0, len(src_nodes)):
        data += "{:<30}=>{:>30}{:>10}\n".format(src_nodes[i], dst_nodes[i], counts[i])
    save_data_to_file(file_name, ip_address, "edges", data)


def save_loops_to_file(file_name, ip_address, all_loops, total_number_of_loops, llen1, llen2):
    loop_len = llen1
    data = "Total number of loops in range {} - {} above count threshold {} is: {}\n" \
        .format(llen1, llen2, lt, total_number_of_loops)
    for loops in all_loops:
        number_of_loops = len(loops)
        data += "------------------------------------------------------------------------\n"
        data += "Number of loops of length {} above count threshold {} : {}\n"\
            .format(loop_len, lt, number_of_loops)
        for loop in loops:
            data += loop.__repr__() + "\n"
        data += "------------------------------------------------------------------------\n"
        loop_len += 1
    save_data_to_file(file_name, ip_address, "loops", data)


def save_overall_data_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "overall", data)


def save_graph_to_json(file_name, ip_address, node_dict, loops=[[]]):
    node_str = ""
    links_str = ""
    max_node_count, max_flows_to_self, max_flows_number = find_max_number_of_edges(node_dict)
    for node_name in node_dict:
        node = node_dict[node_name]
        node_color_group = 0
        node_size = 5 + 10 * node.count / max_node_count
        if node_name in node.edges:  # if node connects to itself -> make node darker
            node_color_group += 5 * len(node.edges[node_name].flows) / max_flows_to_self
        node_str += '{{"id": "{0}", "node_color_group": {1}, "node_size": {2}}},\n'\
            .format(node_name, node_color_group, node_size)
        for edge_dst in node.edges:
            if edge_dst != node_name:
                edge_size = 1 + 150 * len(node.edges[edge_dst].flows) / max_flows_number
                dst_node_size = 5 + 10 * node_dict[edge_dst].count / max_node_count
                # if find_loops.is_node_in_a_loop(edge_dst, loops):
                #     edge_color_group = 1
                # else:
                edge_color_group = 0
                links_str += '{{"source": "{0}", "target": "{1}", "value": {2}, "dst_node_size": {3}, ' \
                             '"edge_color_group": {4}}},\n'\
                    .format(node_name, edge_dst, edge_size, dst_node_size, edge_color_group)
    node_str = node_str[:-2]
    links_str = links_str[:-2]
    graph_json_str = '{{"nodes":[\n{0}\n],\n "links":[\n{1}\n]}}'.format(node_str, links_str)
    save_data_to_file(file_name, ip_address, "graph_json", graph_json_str)
    return graph_json_str


def all_args_to_str(args):
    out_str = args[0]
    for arg in args[1:]:
        out_str += " " + arg
    out_str += "\n"
    return out_str

if __name__ == "__main__":
    if len(sys.argv) >= 3:
        file_name = sys.argv[1]
        if not file_name.endswith(".binetflow"):
            console_print("File name (first argument) must be binetflow. Be sure to check your input file ends with"
                          "\".binetflow\"\n")
            exit()
        curr_dir = sys.argv[0].split("main.py")[0]
        chdir(curr_dir)
        file_name = path.join('data', file_name)
        ip_address = sys.argv[2]
        data = filter_data.read_and_filter_file_only_examined_src_ip(file_name, ip_address)

        filter_nodes_with_one_occurrence, filter_args, alt, et, llen1, llen2, lt, less, no_out, no_outf \
            = process_input_args(sys.argv)

        node_dict, first_node, nodes_ls_in_order = mk_graph(data, filter_args)

        prev_len = len(node_dict)

        overall_data = all_args_to_str(sys.argv)
        console_print(overall_data)

        # -------------------------------------
        # Filtering all nodes that appeared only once
        if not no_out:
            out_str = "Total number of nodes: {}\n".format(prev_len)
            overall_data += out_str
            console_print(out_str)

        if filter_nodes_with_one_occurrence:
            node_dict, nodes_ls_in_order = filter_data.filter_nodes(node_dict, nodes_ls_in_order)
            curr_len = len(node_dict)
            removed_nodes = prev_len - curr_len
            node_compression = float(removed_nodes) / prev_len * 100
            if not no_out:
                out_str = "Number of nodes after filtering nodes with one occurence: {} ({}% node compression)\n"\
                    .format(curr_len, node_compression)
                overall_data += out_str
                console_print(out_str)

        # -------------------------------------
        # Autolooping nodes above threshold
        al_nodes, al_counts = filter_data.find_auto_looping_nodes_and_counts(node_dict, alt)
        if alt > -1:
            if not no_out:
                out_str = "Number of autolooping nodes above threshold: {}\n"\
                    .format(len(al_nodes))
                overall_data += out_str
                console_print(out_str)
                if not less:
                    out_str = "Nodes above threshold with autolooping counts above threshold {}:\n"\
                        .format(alt)
                    print_list_node_names_counts(al_nodes, al_counts)
            if not no_outf:
                save_al_nodes_to_file(file_name, ip_address, al_nodes, al_counts)

        # -------------------------------------
        # Edges with size above threshold
        edge_src_nodes, edge_dst_nodes, e_counts = \
            filter_data.find_nodes_with_edge_size(node_dict, et)
        if et > -1:
            if not no_out:
                out_str = "Number of edges with size above threshold: {}\n"\
                    .format(len(edge_src_nodes))
                overall_data += out_str
                console_print(out_str)
                if not less:
                    out_str = "Edges with size above threshold: {}\n"\
                        .format(et)
                    console_print(out_str)
                    print_list_edges_counts(edge_src_nodes, edge_dst_nodes, e_counts)
            if not no_outf:
                save_edges_to_file(file_name, ip_address, edge_src_nodes, edge_dst_nodes, e_counts)

        # -------------------------------------
        # Loops of given range above given count threshold
        if llen1 > 1:
            all_loops, total_number_of_loops = get_loops_in_range(node_dict, nodes_ls_in_order, llen1, llen2, lt)
            loop_len = llen1
            if not no_out:
                out_str = "Total number of loops in range {} - {} above count threshold {} is: {}\n"\
                    .format(llen1, llen2, lt, total_number_of_loops)
                overall_data += out_str
                for loops in all_loops:
                    number_of_loops = len(loops)
                    if not less:
                        out_str += "------------------------------------------------------------------------\n"
                    out_loop_counts_str = "Number of loops of length {} above count threshold {} : {}\n"\
                        .format(loop_len, lt, number_of_loops)
                    out_str += out_loop_counts_str
                    overall_data += out_loop_counts_str
                    if not less:
                        for loop in loops:
                            out_str += "{}\n".format(loop.__repr__())
                        out_str += "------------------------------------------------------------------------\n"
                    loop_len += 1
                console_print(out_str)
            if not no_outf:
                save_loops_to_file(file_name, ip_address, all_loops, total_number_of_loops, llen1, llen2)

        if not no_outf:
            save_overall_data_to_file(file_name, ip_address, overall_data)

        # -------------------------------------
        # Save graph to json file for web page visualisation
        if not no_outf:
            graph_json_str = save_graph_to_json(file_name, ip_address, node_dict)
            # save graph to json file in current directory, can be immediately visualised in web page
            with open("graph.json", "w") as f:
                f.write(graph_json_str)
    else:
        console_print("There should be at least 2 input arguments:\n"
                      "name of .binetflow (with file extension) file"
                      "(from \"data\" directory)\n and an IP address.\n")
