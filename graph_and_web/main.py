import sys
from os import path, makedirs, chdir
import ntpath
import filter_data
from make_graph import mk_graph, find_max_number_of_edges
from input_processing import process_input_args
from find_loops import get_loops_in_range
from other_functions import console_print
import properties


def save_data_to_file(file_name, ip_address, what_to_save, data):
    dir_name = path.join("output", "data")
    file_name = ntpath.basename(file_name)
    file_name = file_name.split(".binetflow")[0]
    dir_name = path.join(dir_name, file_name, ip_address)
    if not path.isdir(dir_name):
        makedirs(dir_name)
    file_name_ending = ""
    if what_to_save == "graph_json":
        file_name_ending = "_graph.json"
    else:
        if what_to_save == "sl_nodes":
            file_name_ending = "_sl-nodes"
        elif what_to_save == "edges":
            file_name_ending = "_edges"
        elif what_to_save == "loops":
            file_name_ending = "_loops"
        elif what_to_save == "overall":
            file_name_ending = "_overall"
        file_name_ending += ".md"
    file_name += "_" + ip_address + file_name_ending
    with open(path.join(dir_name, file_name), "w") as f:
        f.write(data)


def format_self_looping_nodes_output(nodes, counts):
    out_str = ""
    for i in range(0, len(nodes)):
        out_str += "{:<30}{:>10}\n".format(nodes[i], counts[i])
    return out_str


def save_sl_nodes_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "sl_nodes", data)


def format_edges_output(src_nodes, dst_nodes, counts):
    out_str = ""
    for i in range(0, len(src_nodes)):
        out_str += "{:<30}=>{:>30}{:>10}\n".format(src_nodes[i], dst_nodes[i], counts[i])
    return out_str


def save_edges_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "edges", data)


def format_loops_output(all_loops, llen1, llen2):
    loop_len = llen1
    out_str = ""
    out_str_less = ""
    for loops in all_loops:
        number_of_loops = len(loops)
        out_str += "===============\n"
        number_of_loops_str = "Number of loops of length {}: {}\n"\
            .format(loop_len, number_of_loops)
        out_str_less += number_of_loops_str
        out_str += number_of_loops_str
        for loop in loops:
            out_str += loop.__repr__() + "\n"
        loop_len += 1
    return out_str, out_str_less


def save_loops_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "loops", data)


def save_overall_data_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "overall", data)


def save_graph_to_json(file_name, ip_address, node_dict, loops=[[]]):
    node_str = ""
    links_str = ""
    max_node_count, max_self_loop_count, max_edge_size = find_max_number_of_edges(node_dict)
    if max_node_count < properties.GJSON_MIN_MAX_NODE_COUNT:
        max_node_count = properties.GJSON_MIN_MAX_NODE_COUNT
    if max_self_loop_count < properties.GJSON_MIN_MAX_SELF_LOOP_COUNT:
        max_self_loop_count = properties.GJSON_MIN_MAX_SELF_LOOP_COUNT
    if max_edge_size < properties.GJSON_MIN_MAX_EDGE_SIZE:
        max_edge_size = properties.GJSON_MIN_MAX_EDGE_SIZE
    for node_name in node_dict:
        node = node_dict[node_name]
        node_color_group = properties.GJSON_DEFAULT_NODE_VISUALISATION_COLOR_GROUP
        node_size = \
            properties.GJSON_MIN_NODE_VISUALISATION_SIZE + \
            properties.GJSON_VISULISATION_RANGE_SIZE_OF_NODE_SIZE * node.count / max_node_count
        if node_name in node.edges:  # if node connects to itself -> make node darker
            node_color_group += \
                (properties.GJSON_DEFAULT_NODE_VISUALISATION_COLOR_GROUPS_COUNT - 1) * \
                len(node.edges[node_name].flows) / max_self_loop_count
        node_str += '{{"id": "{0}", "node_color_group": {1}, "node_size": {2}}},\n'\
            .format(node_name, node_color_group, node_size)
        for edge_dst in node.edges:
            if edge_dst != node_name:
                edge_size = \
                    properties.GJSON_MIN_EDGE_VISUALISATION_SIZE + \
                    properties.GJSON_VISULISATION_RANGE_SIZE_OF_EDGE_SIZE * \
                    len(node.edges[edge_dst].flows) / max_edge_size
                dst_node_size = properties.GJSON_MIN_NODE_VISUALISATION_SIZE + \
                                properties.GJSON_VISULISATION_RANGE_SIZE_OF_NODE_SIZE * \
                                node_dict[edge_dst].count / max_node_count
                edge_color_group = properties.GJSON_DEFAULT_EDGE_VISUALISATION_COLOR_GROUP
                # if find_loops.is_node_in_a_loop(edge_dst, loops):
                #     edge_color_group = 1
                links_str += '{{"source": "{0}", "target": "{1}", "value": {2}, "dst_node_size": {3}, ' \
                             '"edge_color_group": {4}}},\n'\
                    .format(node_name, edge_dst, edge_size, dst_node_size, edge_color_group)
    node_str = node_str[:-2]
    links_str = links_str[:-2]
    graph_json_str = '{{"nodes":[\n{0}\n],\n "links":[\n{1}\n]}}'.format(node_str, links_str)
    save_data_to_file(file_name, ip_address, "graph_json", graph_json_str)
    return graph_json_str


def all_args_to_str(args):
    out_str = args[0]
    for arg in args[1:]:
        out_str += " " + arg
    out_str += "\n"
    return out_str


def error_exit_program(str_output):
    console_print(str_output)
    exit()


def main_function(path_to_script, program_args_without_path):
    if len(program_args_without_path) >= 2:
        file_name = program_args_without_path[0]
        if not file_name.endswith(".binetflow"):
            error_exit_program("File name (first argument) must be binetflow. Be sure to check your input file "
                               "ends with\".binetflow\"\n")
        chdir(path_to_script)
        ip_address = sys.argv[2]
        data = filter_data.read_and_filter_file_only_examined_src_ip(file_name, ip_address)
        if data == "":
            error_exit_program("Nothing was read from file \"{}\", be sure to check if specified IP address \"{}\" "
                               "is somewhere in the file as source IP address.\n".format(file_name, ip_address))
        if data == "error":
            error_exit_program("File \"{}\" does not exist.\n".format(file_name))

        filter_nodes_with_one_occurrence, filter_args, slt, et, llen1, llen2, lt, less, no_out, no_outf, gjson \
            = process_input_args(sys.argv)

        overall_data = all_args_to_str(sys.argv)
        console_print(overall_data)

        node_dict, first_node, nodes_ls_in_order = mk_graph(data, filter_args)

        prev_len = len(node_dict)

        # -------------------------------------
        # Filtering all nodes that appeared only once
        if not no_out:
            out_str = "Total number of nodes: {}\n".format(prev_len)
            overall_data += out_str
            console_print(out_str)

        if filter_nodes_with_one_occurrence:
            node_dict, nodes_ls_in_order = filter_data.filter_nodes(node_dict, nodes_ls_in_order)
            curr_len = len(node_dict)
            removed_nodes = prev_len - curr_len
            node_compression = float(removed_nodes) / prev_len * 100
            if not no_out:
                out_str = "Number of nodes after filtering nodes with one occurence: {} ({}% node compression)\n"\
                    .format(curr_len, node_compression)
                overall_data += out_str
                console_print(out_str)

        # -------------------------------------
        # Self-looping nodes above threshold
        sl_nodes, sl_counts = filter_data.find_self_looping_nodes_and_counts(node_dict, slt)
        if slt > -1:
            data = format_self_looping_nodes_output(sl_nodes, sl_counts)
            if not no_out:
                out_str = "Number of self-looping nodes with counts above threshold {}: {}\n"\
                    .format(slt, len(sl_nodes))
                overall_data += out_str
                if not less:
                    out_str += "---------------\n"
                    out_str += "Nodes with self-looping counts above threshold {}:\n"\
                        .format(slt)
                    out_str += data
                    out_str += "---------------\n"
                console_print(out_str)
            if not no_outf:
                save_sl_nodes_to_file(file_name, ip_address, data)

        # -------------------------------------
        # Edges with size above threshold
        edge_src_nodes, edge_dst_nodes, e_counts = \
            filter_data.find_nodes_with_edge_size(node_dict, et)
        if et > -1:
            data = format_edges_output(edge_src_nodes, edge_dst_nodes, e_counts)
            if not no_out:
                out_str = "Number of edges with size above threshold {}: {}\n"\
                    .format(et, len(edge_src_nodes))
                overall_data += out_str
                if not less:
                    out_str += "Edges with size above threshold: {}\n"\
                        .format(et)
                    out_str += "---------------\n"
                    out_str += data
                    out_str += "---------------\n"
                console_print(out_str)
            if not no_outf:
                save_edges_to_file(file_name, ip_address, data)

        # -------------------------------------
        # Loops of given range above given count threshold
        if lt > -1:
            all_loops, total_number_of_loops = get_loops_in_range(node_dict, nodes_ls_in_order, llen1, llen2, lt)
            loop_len = llen1
            data, data_less = format_loops_output(all_loops, llen1, llen2)
            if not no_out:
                out_str = "Total number of loops in range {} - {} above count threshold {} is: {}\n"\
                    .format(llen1, llen2, lt, total_number_of_loops)
                overall_data += out_str
                overall_data += data_less
                if less:
                    out_str += data_less
                else:
                    out_str += data
                    out_str += "---------------\n"
                console_print(out_str)
            if not no_outf:
                save_loops_to_file(file_name, ip_address, data)

        if not no_outf:
            save_overall_data_to_file(file_name, ip_address, overall_data)

        # -------------------------------------
        # Save graph to json file for web page visualisation
        if gjson:
            graph_json_str = save_graph_to_json(file_name, ip_address, node_dict)
            # save graph to json file in current directory, can be immediately visualised in web page
            with open("graph.json", "w") as f:
                f.write(graph_json_str)
    else:
        console_print("There should be at least 2 input arguments:\n"
                      "name of .binetflow (with file extension) file"
                      "(from \"data\" directory)\n and an IP address.\n")

if __name__ == "__main__":
    main_function(sys.path[0], sys.argv[1:])
