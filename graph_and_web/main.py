import sys
import ntpath
import filter_data
import features_search
from make_graph import mk_graph
from input_processing import process_input_args
from other_functions import console_print, error_exit_program
from saving_to_files import save_cycles_to_file, save_edges_to_file, save_graph_to_json, save_overall_data_to_file, \
    save_nodes_to_file, save_sl_nodes_to_file
import properties


def format_csv_output(path_to_file, ip_address, label, filter_args, f1, nt, slt, et, ct, freq_port,
                      most_freq_port_ratio, freq_protocol, most_freq_protocol_ratio,
                      nodes_tot_no_f1, nodes_tot, f1_ratio, nodes_over_thr, nodes_over_thr_ratio, self_looping_nodes,
                      edges_tot_no_f1, edges_tot, edges_thr,
                      edges_thr_ratio, cycles_tot, clen1, cycles_counts):
    file_name = ntpath.basename(path_to_file).split(properties.STR_BINETFLOW_EXT)[0]

    out_str = "FileName,IP,Label,FILTER,F1,NT,SLT,ET,CT,MostFreqPort,%MostFreqPortRatio,MostFreqProto," \
              "%MostFreqProtoRatio,#nodesTotNoF1,#nodesTot,%f1Ratio," \
              "#nodesThr,%nodesThrRatio,#selfLoop,#edgesTotNoF1,#edgesTot,#edgesThr,%edgesThrRatio,#cyclesTot"

    out_str_end = ""
    for i in range(0, len(cycles_counts)):
        out_str += ",#cycle{}".format(i + clen1)
        out_str_end += ",{}".format(cycles_counts[i])

    out_str += "\n"
    out_str_end += "\n"

    out_str += "{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}" \
        .format(file_name, ip_address, label, filter_args, f1, nt, slt, et, ct, freq_port, most_freq_port_ratio,
                freq_protocol, most_freq_protocol_ratio,
                nodes_tot_no_f1, nodes_tot, f1_ratio,
                nodes_over_thr, nodes_over_thr_ratio, self_looping_nodes, edges_tot_no_f1, edges_tot, edges_thr,
                edges_thr_ratio, cycles_tot)
    out_str += out_str_end
    return out_str


def format_nodes_output(nodes, counts):
    out_str = ""
    for i in range(0, len(nodes)):
        out_str += "{:<30}{:>10}\n".format(nodes[i], counts[i])
    return out_str


def format_edges_output(src_nodes, dst_nodes, counts):
    out_str = ""
    for i in range(0, len(src_nodes)):
        out_str += "{:<30}=>{:>30}{:>10}\n".format(src_nodes[i], dst_nodes[i], counts[i])
    return out_str


def format_cycles_output(all_cycles, clen1, csv_output, no_outf):
    cycle_len = clen1
    out_str = ""
    out_str_less = ""
    cycles_counts = []
    for cycles in all_cycles:
        number_of_cycles = len(cycles)
        cycles_counts.append(number_of_cycles)
        if csv_output and no_outf:
            out_str += "===============\n"
            number_of_cycles_str = "Number of cycles of length {}: {}\n" \
                .format(cycle_len, number_of_cycles)
            out_str_less += number_of_cycles_str
            out_str += number_of_cycles_str
            for cycle in cycles:
                out_str += cycle.__repr__() + "\n"
        cycle_len += 1
    return out_str, out_str_less, cycles_counts


def all_args_to_str(args):
    out_str = args[0]
    for arg in args[1:]:
        out_str += " " + arg
    out_str += "\n"
    return out_str


def read_args_and_data(args):
    path_to_file, ip_address, f1_filter, filter_args, nt, slt, et, llen1, llen2, ct, \
    csv_output, less, no_out, no_outf, gjson, ntg, sltg, etg, label = process_input_args(args)

    if path_to_file == properties.STR_EMPTY or ip_address == properties.STR_EMPTY:
        error_exit_program(properties.ERROR_STR_MISSING_PATH_OR_IP)

    if not path_to_file.endswith(properties.STR_BINETFLOW_EXT):
        error_exit_program(properties.ERROR_STR_NOT_END_WITH_EXT.format(path_to_file, properties.STR_BINETFLOW_EXT))

    node_dict, nodes_ls_in_order = mk_graph(path_to_file, ip_address, filter_args)

    if node_dict == properties.STR_EMPTY:
        error_exit_program(properties.ERROR_STR_EMPTY_DATA.format(path_to_file, ip_address))

    if node_dict == properties.STR_ERROR:
        error_exit_program(properties.ERROR_STR_FILE_NOT_EXIST.format(path_to_file))

    return node_dict, nodes_ls_in_order, path_to_file, ip_address, f1_filter, filter_args, nt, slt, et, llen1, llen2, ct, \
           csv_output, less, no_out, no_outf, gjson, ntg, sltg, etg, label


def main_function(args):
    node_dict, nodes_ls_in_order, path_to_file, ip_address, f1_filter, filter_args, nt, slt, et, clen1, clen2, ct, \
    csv_output, less, no_out, no_outf, gjson, ntg, sltg, etg, label = read_args_and_data(args)

    out_str = all_args_to_str(args)
    overall_data = out_str

    # -------------------------------------
    # Total number of nodes
    total_number_of_nodes_no_f1 = total_number_of_nodes = features_search.get_number_of_all_nodes(node_dict)
    temp_str = "Total number of nodes without \"f1\" filter: {}\n".format(total_number_of_nodes_no_f1)
    out_str += temp_str
    overall_data += temp_str

    # -------------------------------------
    # Total number of edges before f1
    total_number_of_edges_no_f1 = features_search.get_number_of_all_edges(node_dict)
    temp_str = "Total number of edges without \"f1\" filter: {}\n".format(total_number_of_edges_no_f1)
    out_str += temp_str
    overall_data += temp_str

    # -------------------------------------
    # Filtering all nodes that appeared only once
    f1_ratio = ""
    if f1_filter:
        node_dict, nodes_ls_in_order = filter_data.filter_f1(node_dict, nodes_ls_in_order)
        number_of_removed_nodes = total_number_of_nodes - len(node_dict)
        if total_number_of_nodes > 0:
            f1_ratio = float(number_of_removed_nodes) / total_number_of_nodes * 100
        else:
            f1_ratio = 0
        total_number_of_nodes -= number_of_removed_nodes
        temp_str = "Number of nodes after \"f1\" filter: {}\n" \
                   "Node compression: {}%\n" \
            .format(total_number_of_nodes, f1_ratio)
        out_str += temp_str
        overall_data += temp_str

    # -------------------------------------
    # Most frequent port and protocol and its ratios
    most_freq_port, most_freq_port_ratio, most_freq_protocol, most_freq_protocol_ratio = \
        features_search.get_most_frequent_port_and_its_ratio(node_dict)
    temp_str = "Most frequent port: {}\nRatio of most frequent port: {}%\n" \
               "Most frequent protocol: {}\nRatio of most frequent protocol: {}%\n" \
        .format(most_freq_port, most_freq_port_ratio, most_freq_protocol, most_freq_protocol_ratio)
    out_str += temp_str
    overall_data += temp_str

    # -------------------------------------
    # Nodes with count above threshold
    number_of_nodes_above_threshold = ""
    ratio_of_nodes_above_threshold = ""
    nodes_data = ""
    if nt > -1:
        nodes, counts = features_search.get_nodes_and_counts(node_dict, nt)
        nodes_data = format_nodes_output(nodes, counts)
        number_of_nodes_above_threshold = len(nodes)
        temp_str = "Number of nodes with counts above threshold {}: {}\n" \
            .format(slt, number_of_nodes_above_threshold)
        out_str += temp_str
        overall_data += temp_str
        if not no_out:
            if not less:
                out_str += "---------------\n"
                out_str += "Nodes with counts above threshold {}:\n" \
                    .format(nt)
                out_str += nodes_data
                out_str += "---------------\n"

        # -------------------------------------
        # Ratio of nodes with counts above threshold out of total number of nodes
        if total_number_of_nodes > 0:
            ratio_of_nodes_above_threshold = float(number_of_nodes_above_threshold) / total_number_of_nodes * 100
        else:
            ratio_of_nodes_above_threshold = 0
        temp_str = "Ratio of nodes above threshold {}: {}%\n".format(nt, ratio_of_nodes_above_threshold)
        out_str += temp_str
        overall_data += temp_str

    # -------------------------------------
    # Self-looping nodes with count above threshold
    number_of_self_looping_nodes = ""
    sl_nodes_data = ""
    if slt > -1:
        sl_nodes, sl_counts = features_search.get_self_looping_nodes_and_counts(node_dict, slt)
        sl_nodes_data = format_nodes_output(sl_nodes, sl_counts)
        number_of_self_looping_nodes = len(sl_nodes)
        temp_str = "Number of self-looping nodes with counts above threshold {}: {}\n" \
            .format(slt, number_of_self_looping_nodes)
        out_str += temp_str
        overall_data += temp_str
        if not no_out:
            if not less:
                out_str += "---------------\n"
                out_str += "Nodes with self-looping counts above threshold {}:\n" \
                    .format(slt)
                out_str += sl_nodes_data
                out_str += "---------------\n"

    # -------------------------------------
    # Total number of edges
    total_number_of_edges = features_search.get_number_of_all_edges(node_dict)
    temp_str = "Total number of edges: {}\n".format(total_number_of_edges)
    out_str += temp_str
    overall_data += temp_str

    # -------------------------------------
    # Edges with size above threshold
    number_of_edges_above_threshold = ""
    ratio_of_edges_above_threshold = ""
    edges_data = ""
    if et > -1:
        edge_src_nodes, edge_dst_nodes, e_counts = \
            features_search.get_nodes_with_edge_size(node_dict, et)
        edges_data = format_edges_output(edge_src_nodes, edge_dst_nodes, e_counts)
        number_of_edges_above_threshold = len(edge_src_nodes)
        temp_str = "Number of edges with repetition above threshold {}: {}\n" \
            .format(et, number_of_edges_above_threshold)
        out_str += temp_str
        overall_data += temp_str
        if not no_out:
            if not less:
                out_str += "Edges with repetition above threshold: {}\n" \
                    .format(et)
                out_str += "---------------\n"
                out_str += edges_data
                out_str += "---------------\n"

        # -------------------------------------
        # Ratio of edges above threshold out of total number of edges
        if total_number_of_edges > 0:
            ratio_of_edges_above_threshold = float(number_of_edges_above_threshold) / total_number_of_edges * 100
        else:
            ratio_of_edges_above_threshold = 0
        temp_str = "Ratio of edges above threshold {}: {}%\n".format(et, ratio_of_edges_above_threshold)
        out_str += temp_str
        overall_data += temp_str

    # -------------------------------------
    # Cycles of given range above given count threshold
    total_number_of_cycles = ""
    cycles_counts = []
    cycles_data = ""
    all_cycles = []
    if ct > -1:
        all_cycles, total_number_of_cycles = \
            features_search.find_cycles_in_range(nodes_ls_in_order, clen1, clen2, ct)
        cycles_data, data_less, cycles_counts = format_cycles_output(all_cycles, clen1, csv_output, no_outf)
        temp_str = "Total number of cycles in range {} - {} above count threshold {} is: {}\n" \
            .format(clen1, clen2, ct, total_number_of_cycles)
        out_str += temp_str
        overall_data += temp_str
        overall_data += data_less
        if not no_out:
            if less:
                out_str += data_less
            else:
                out_str += cycles_data
                out_str += "---------------\n"

    if csv_output:
        out_str = format_csv_output(path_to_file, ip_address, label, filter_args, f1_filter, nt, slt, et, ct,
                                    most_freq_port, most_freq_port_ratio, most_freq_protocol,
                                    most_freq_protocol_ratio,
                                    total_number_of_nodes_no_f1, total_number_of_nodes, f1_ratio,
                                    number_of_nodes_above_threshold, ratio_of_nodes_above_threshold,
                                    number_of_self_looping_nodes, total_number_of_edges_no_f1,
                                    total_number_of_edges,
                                    number_of_edges_above_threshold, ratio_of_edges_above_threshold,
                                    total_number_of_cycles, clen1, cycles_counts)
        console_print(out_str)
    elif not no_out:
        console_print(out_str)
    if not no_outf:
        save_overall_data_to_file(path_to_file, ip_address, overall_data)
        save_nodes_to_file(path_to_file, ip_address, nodes_data)
        save_sl_nodes_to_file(path_to_file, ip_address, sl_nodes_data)
        save_edges_to_file(path_to_file, ip_address, edges_data)
        save_cycles_to_file(path_to_file, ip_address, cycles_data)

    # -------------------------------------
    # Save graph to json file for web page visualisation
    if gjson:
        graph_json_str = \
            save_graph_to_json(path_to_file, ip_address, node_dict, ntg, nt, sltg, slt, etg, et, all_cycles)
        # save graph to json file in current directory, can be immediately visualised in web page
        with open("graph.json", "w") as f:
            f.write(graph_json_str)


if __name__ == "__main__":
    main_function(sys.argv[1:])
