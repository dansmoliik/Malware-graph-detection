import sys
from os import path, makedirs
import ntpath
import filter_data
import features_search
from make_graph import mk_graph, find_max_number_of_edges
from input_processing import process_input_args
from other_functions import console_print
import properties


def format_csv_output(path_to_file, ip_address, label, nodes_tot, f1_ratio, nodes_over_thr, nodes_over_thr_ratio,
                      self_looping_nodes, edges_tot, edges_thr, edges_thr_ratio, loops_tot, llen1=2,
                      loop_counts=[]):
    file_name = ntpath.basename(path_to_file).split(properties.STR_BINETFLOW_EXT)[0]

    out_str = "FileName,IP,Label,#nodesTot,%f1Ratio,#nodesThr,#nodesThrRatio,#selfLoop,#edgesTot,#edgesThr," \
              "#edgesThrRatio,#loopsTot"

    out_str_end = ""
    for i in range(0, len(loop_counts)):
        out_str += ",#loop{}".format(i + llen1)
        out_str_end += ",{}".format(loop_counts[i])

    out_str += "\n"
    out_str_end += "\n"

    out_str += "{},{},{},{},{},{},{},{},{},{},{},{}"\
        .format(file_name, ip_address, label, nodes_tot, f1_ratio, nodes_over_thr, nodes_over_thr_ratio,
                self_looping_nodes, edges_tot, edges_thr, edges_thr_ratio, loops_tot)
    out_str += out_str_end
    return out_str


def save_data_to_file(file_name, ip_address, what_to_save, data):
    dir_name = path.join("output", "data")
    file_name = ntpath.basename(file_name)
    file_name = file_name.split(".binetflow")[0]
    dir_name = path.join(dir_name, file_name, ip_address)
    if not path.isdir(dir_name):
        makedirs(dir_name)
    file_name_ending = ""
    if what_to_save == "graph_json":
        file_name_ending = "_graph.json"
    else:
        if what_to_save == "nodes":
            file_name_ending = "_nodes"
        elif what_to_save == "sl_nodes":
            file_name_ending = "_sl-nodes"
        elif what_to_save == "edges":
            file_name_ending = "_edges"
        elif what_to_save == "loops":
            file_name_ending = "_loops"
        elif what_to_save == "overall":
            file_name_ending = "_overall"
        file_name_ending += ".md"
    file_name += "_" + ip_address + file_name_ending
    with open(path.join(dir_name, file_name), "w") as f:
        f.write(data)


def format_nodes_output(nodes, counts):
    out_str = ""
    for i in range(0, len(nodes)):
        out_str += "{:<30}{:>10}\n".format(nodes[i], counts[i])
    return out_str


def save_nodes_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "nodes", data)


def save_sl_nodes_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "sl_nodes", data)


def format_edges_output(src_nodes, dst_nodes, counts):
    out_str = ""
    for i in range(0, len(src_nodes)):
        out_str += "{:<30}=>{:>30}{:>10}\n".format(src_nodes[i], dst_nodes[i], counts[i])
    return out_str


def save_edges_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "edges", data)


def format_loops_output(all_loops, llen1):
    loop_len = llen1
    out_str = ""
    out_str_less = ""
    loop_counts = []
    for loops in all_loops:
        number_of_loops = len(loops)
        loop_counts.append(number_of_loops)
        out_str += "===============\n"
        number_of_loops_str = "Number of loops of length {}: {}\n"\
            .format(loop_len, number_of_loops)
        out_str_less += number_of_loops_str
        out_str += number_of_loops_str
        for loop in loops:
            out_str += loop.__repr__() + "\n"
        loop_len += 1
    return out_str, out_str_less, loop_counts


def save_loops_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "loops", data)


def save_overall_data_to_file(file_name, ip_address, data):
    save_data_to_file(file_name, ip_address, "overall", data)


def save_graph_to_json(file_name, ip_address, node_dict, loops=[[]]):
    node_str = ""
    links_str = ""
    max_node_count, max_self_loop_count, max_edge_size = find_max_number_of_edges(node_dict)
    if max_node_count < properties.GJSON_MIN_MAX_NODE_COUNT:
        max_node_count = properties.GJSON_MIN_MAX_NODE_COUNT
    if max_self_loop_count < properties.GJSON_MIN_MAX_SELF_LOOP_COUNT:
        max_self_loop_count = properties.GJSON_MIN_MAX_SELF_LOOP_COUNT
    if max_edge_size < properties.GJSON_MIN_MAX_EDGE_SIZE:
        max_edge_size = properties.GJSON_MIN_MAX_EDGE_SIZE
    for node_name in node_dict:
        node = node_dict[node_name]
        node_color_group = properties.GJSON_DEFAULT_NODE_VISUALISATION_COLOR_GROUP
        node_size = \
            properties.GJSON_MIN_NODE_VISUALISATION_SIZE + \
            properties.GJSON_VISULISATION_RANGE_SIZE_OF_NODE_SIZE * node.count / max_node_count
        if node_name in node.edges:  # if node connects to itself -> make node darker
            node_color_group += \
                (properties.GJSON_DEFAULT_NODE_VISUALISATION_COLOR_GROUPS_COUNT - 1) * \
                len(node.edges[node_name].flows) / max_self_loop_count
        node_str += '{{"id": "{0}", "node_color_group": {1}, "node_size": {2}}},\n'\
            .format(node_name, node_color_group, node_size)
        for edge_dst in node.edges:
            if edge_dst != node_name:
                edge_size = \
                    properties.GJSON_MIN_EDGE_VISUALISATION_SIZE + \
                    properties.GJSON_VISULISATION_RANGE_SIZE_OF_EDGE_SIZE * \
                    len(node.edges[edge_dst].flows) / max_edge_size
                dst_node_size = properties.GJSON_MIN_NODE_VISUALISATION_SIZE + \
                                properties.GJSON_VISULISATION_RANGE_SIZE_OF_NODE_SIZE * \
                                node_dict[edge_dst].count / max_node_count
                edge_color_group = properties.GJSON_DEFAULT_EDGE_VISUALISATION_COLOR_GROUP
                # if find_loops.is_node_in_a_loop(edge_dst, loops):
                #     edge_color_group = 1
                links_str += '{{"source": "{0}", "target": "{1}", "value": {2}, "dst_node_size": {3}, ' \
                             '"edge_color_group": {4}}},\n'\
                    .format(node_name, edge_dst, edge_size, dst_node_size, edge_color_group)
    node_str = node_str[:-2]
    links_str = links_str[:-2]
    graph_json_str = '{{"nodes":[\n{0}\n],\n "links":[\n{1}\n]}}'.format(node_str, links_str)
    save_data_to_file(file_name, ip_address, "graph_json", graph_json_str)
    return graph_json_str


def all_args_to_str(args):
    out_str = args[0]
    for arg in args[1:]:
        out_str += " " + arg
    out_str += "\n"
    return out_str


def error_exit_program(str_output):
    console_print(str_output)
    exit()


def read_args_and_data(args):
        path_to_file, ip_address, f1_filter, filter_args, nt, slt, et, llen1, llen2, lt, \
            csv_output, less, no_out, no_outf, gjson, label = process_input_args(args)

        if path_to_file == properties.STR_EMPTY or ip_address == properties.STR_EMPTY:
            error_exit_program(properties.ERROR_STR_MISSING_PATH_OR_IP)

        if not path_to_file.endswith(properties.STR_BINETFLOW_EXT):
            error_exit_program(properties.ERROR_STR_NOT_BINETFLOW_EXT)

        data = filter_data.read_and_filter_file_only_examined_src_ip(path_to_file, ip_address)

        if data == properties.STR_EMPTY:
            error_exit_program(properties.ERROR_STR_EMPTY_DATA.format(path_to_file, ip_address))

        if data == properties.STR_ERROR:
            error_exit_program(properties.ERROR_STR_FILE_NOT_EXIT.format(path_to_file))

        return data, path_to_file, ip_address, f1_filter, filter_args, nt, slt, et, llen1, llen2, lt, \
            csv_output, less, no_out, no_outf, gjson, label


def main_function(args):
    if len(args) >= 2:
        data, path_to_file, ip_address, f1_filter, filter_args, nt, slt, et, llen1, llen2, lt, \
            csv_output, less, no_out, no_outf, gjson, label = read_args_and_data(args)

        out_str = all_args_to_str(args)
        overall_data = out_str

        node_dict, first_node, nodes_ls_in_order = mk_graph(data, filter_args)

        # -------------------------------------
        # Total number of nodes
        total_number_of_nodes = features_search.get_number_of_all_nodes(node_dict)
        out_str += "Total number of nodes without \"f1\" filter: {}\n".format(total_number_of_nodes)
        overall_data += out_str

        # -------------------------------------
        # Filtering all nodes that appeared only once
        f1_ratio = ""
        if f1_filter:
            node_dict, nodes_ls_in_order = filter_data.filter_nodes(node_dict, nodes_ls_in_order)
            number_of_removed_nodes = total_number_of_nodes - len(node_dict)
            f1_ratio = float(number_of_removed_nodes) / total_number_of_nodes * 100
            total_number_of_nodes -= number_of_removed_nodes
            out_str += "Number of nodes after \"f1\" filter: {}\n" \
                "Node compression: {}%\n"\
                .format(total_number_of_nodes, f1_ratio)
            overall_data += out_str

        # -------------------------------------
        # Nodes with count above threshold
        number_of_nodes_above_threshold = ""
        ratio_of_nodes_above_threshold = ""
        if nt > -1:
            nodes, counts = features_search.get_nodes_and_counts(node_dict, nt)
            data = format_nodes_output(nodes, counts)
            number_of_nodes_above_threshold = len(nodes)
            out_str += "Number of nodes with counts above threshold {}: {}\n"\
                .format(slt, number_of_nodes_above_threshold)
            overall_data += out_str
            if not no_out:
                if not less:
                    out_str += "---------------\n"
                    out_str += "Nodes with counts above threshold {}:\n"\
                        .format(nt)
                    out_str += data
                    out_str += "---------------\n"
            if not no_outf:
                save_nodes_to_file(path_to_file, ip_address, data)

            # -------------------------------------
            # Ratio of nodes with counts above threshold out of total number of nodes
            ratio_of_nodes_above_threshold = float(number_of_nodes_above_threshold) / total_number_of_nodes * 100
            out_str += "Ratio of nodes above threshold {}: {}%\n".format(nt, ratio_of_nodes_above_threshold)
            overall_data += out_str

        # -------------------------------------
        # Self-looping nodes with count above threshold
        number_of_self_looping_nodes = ""
        if slt > -1:
            sl_nodes, sl_counts = features_search.get_self_looping_nodes_and_counts(node_dict, slt)
            data = format_nodes_output(sl_nodes, sl_counts)
            number_of_self_looping_nodes = len(sl_nodes)
            out_str += "Number of self-looping nodes with counts above threshold {}: {}\n"\
                .format(slt, number_of_self_looping_nodes)
            overall_data += out_str
            if not no_out:
                if not less:
                    out_str += "---------------\n"
                    out_str += "Nodes with self-looping counts above threshold {}:\n"\
                        .format(slt)
                    out_str += data
                    out_str += "---------------\n"
            if not no_outf:
                save_sl_nodes_to_file(path_to_file, ip_address, data)

        # -------------------------------------
        # Total number of edges
        total_number_of_edges = features_search.get_number_of_all_edges(node_dict)
        out_str += "Total number of edges: {}\n".format(total_number_of_edges)
        overall_data += out_str

        # -------------------------------------
        # Edges with size above threshold
        number_of_edges_above_threshold = ""
        ratio_of_edges_above_threshold = ""
        if et > -1:
            edge_src_nodes, edge_dst_nodes, e_counts = \
                features_search.get_nodes_with_edge_size(node_dict, et)
            data = format_edges_output(edge_src_nodes, edge_dst_nodes, e_counts)
            number_of_edges_above_threshold = len(edge_src_nodes)
            out_str += "Number of edges with size above threshold {}: {}\n"\
                .format(et, number_of_edges_above_threshold)
            overall_data += out_str
            if not no_out:
                if not less:
                    out_str += "Edges with size above threshold: {}\n"\
                        .format(et)
                    out_str += "---------------\n"
                    out_str += data
                    out_str += "---------------\n"
            if not no_outf:
                save_edges_to_file(path_to_file, ip_address, data)

            # -------------------------------------
            # Ratio of edges above threshold out of total number of edges
            ratio_of_edges_above_threshold = float(number_of_edges_above_threshold) / total_number_of_edges * 100
            out_str += "Ratio of edges above threshold {}: {}%\n".format(et, ratio_of_edges_above_threshold)
            overall_data += out_str

        # -------------------------------------
        # Loops of given range above given count threshold
        total_number_of_loops = ""
        loop_counts = []
        if lt > -1:
            all_loops, total_number_of_loops = \
                features_search.find_loops_in_range(nodes_ls_in_order, llen1, llen2, lt)
            data, data_less, loop_counts = format_loops_output(all_loops, llen1)
            out_str += "Total number of loops in range {} - {} above count threshold {} is: {}\n"\
                .format(llen1, llen2, lt, total_number_of_loops)
            overall_data += out_str
            overall_data += data_less
            if not no_out:
                if less:
                    out_str += data_less
                else:
                    out_str += data
                    out_str += "---------------\n"
            if not no_outf:
                save_loops_to_file(path_to_file, ip_address, data)

        if csv_output:
            out_str = format_csv_output(path_to_file, ip_address, label, total_number_of_nodes, f1_ratio,
                                        number_of_nodes_above_threshold, ratio_of_nodes_above_threshold,
                                        number_of_self_looping_nodes, total_number_of_edges,
                                        number_of_edges_above_threshold, ratio_of_edges_above_threshold,
                                        total_number_of_loops, llen1, loop_counts)
            console_print(out_str)
        elif not no_out:
            console_print(out_str)
        if not no_outf:
            save_overall_data_to_file(path_to_file, ip_address, overall_data)

        # -------------------------------------
        # Save graph to json file for web page visualisation
        if gjson:
            graph_json_str = save_graph_to_json(path_to_file, ip_address, node_dict)
            # save graph to json file in current directory, can be immediately visualised in web page
            with open("graph.json", "w") as f:
                f.write(graph_json_str)
    else:
        console_print(properties.ERROR_NOT_ENOUGHT_ARGS)

if __name__ == "__main__":
    main_function(sys.argv[1:])
